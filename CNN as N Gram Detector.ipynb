{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4040b83",
   "metadata": {},
   "source": [
    "CNN has been used intensively in image processing tasks. However, what about in text? is it feasible to use it in text? and what kind of output will it be translated when we're using CNN in text?\n",
    "\n",
    "Quoted from [Yoav Goldberg's book](https://www.amazon.com/Language-Processing-Synthesis-Lectures-Technologies/dp/1627052984)\n",
    "> The 1D convolution approach described so far can be thought of as ngram detector. A convolution layer with a windows of size k is learning to identify indicative k-grams in the input.\n",
    "\n",
    "\n",
    "\n",
    "So when we use 1D CNN on text, we approximate a function to determine which texts/ which n-grams are important to a task.\n",
    "\n",
    "**In this short notebook, I will make experiement what kind of \"importance\" will 1D CNN detect when given a text classification task.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13ceba8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63f66f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"%config Completer.use_jedi = False\";\n",
       "                var nbb_formatted_code = \"%config Completer.use_jedi = False\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e488a931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"import torch\\nimport torch.nn as nn\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom tqdm.notebook import tqdm\\nfrom torch.utils.data import Dataset, DataLoader\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom torch.nn import functional as F\\nfrom torch.optim import Adam\\nimport numpy as np\\nfrom IPython.core.display import HTML\\nfrom copy import copy\";\n",
       "                var nbb_formatted_code = \"import torch\\nimport torch.nn as nn\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split\\nfrom tqdm.notebook import tqdm\\nfrom torch.utils.data import Dataset, DataLoader\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom torch.nn import functional as F\\nfrom torch.optim import Adam\\nimport numpy as np\\nfrom IPython.core.display import HTML\\nfrom copy import copy\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "from IPython.core.display import HTML\n",
    "from copy import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5453bd0",
   "metadata": {},
   "source": [
    "Here, I'll experiment with BBC News data from [kaggle](https://www.kaggle.com/c/learn-ai-bbc). The data has been pre-downloaded into my disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e2b7099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"df = pd.read_csv(\\\"data/BBC News Train.csv\\\")\";\n",
       "                var nbb_formatted_code = \"df = pd.read_csv(\\\"data/BBC News Train.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/BBC News Train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee6042d",
   "metadata": {},
   "source": [
    "First thing first, I'll make 2 variables `texts` and `labels` so I could use `scikit`'s `train_test_split` function to split that training data, into 20% test set and the rest will be used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4ec8416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"texts = df.Text.values\\nlabels = df.Category.values\";\n",
       "                var nbb_formatted_code = \"texts = df.Text.values\\nlabels = df.Category.values\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts = df.Text.values\n",
    "labels = df.Category.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fc81186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"X_train, X_test, y_train, y_test = train_test_split(\\n    texts, labels, train_size=0.8, random_state=22\\n)\";\n",
       "                var nbb_formatted_code = \"X_train, X_test, y_train, y_test = train_test_split(\\n    texts, labels, train_size=0.8, random_state=22\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, labels, train_size=0.8, random_state=22\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bcb8c2",
   "metadata": {},
   "source": [
    "Next I will define `Vocabulary` and `LabelVocabulary` to transform `texts` and `labels` into \"encoded\" version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0429f329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"class LabelVocabulary(object):\\n    def __init__(self):\\n        self._label_encoder = LabelEncoder()\\n\\n    def fit(self, labels):\\n        self._label_encoder.fit(labels)\\n\\n    def to_index(self, label):\\n        return self._label_encoder.transform([label])[0]\\n\\n    def to_indexes(self, labels):\\n        return self._label_encoder.transform(labels)\\n\\n    def to_labels(self, indexes):\\n        return self._label_encoder.inverse_transform(indexes)\";\n",
       "                var nbb_formatted_code = \"class LabelVocabulary(object):\\n    def __init__(self):\\n        self._label_encoder = LabelEncoder()\\n\\n    def fit(self, labels):\\n        self._label_encoder.fit(labels)\\n\\n    def to_index(self, label):\\n        return self._label_encoder.transform([label])[0]\\n\\n    def to_indexes(self, labels):\\n        return self._label_encoder.transform(labels)\\n\\n    def to_labels(self, indexes):\\n        return self._label_encoder.inverse_transform(indexes)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class LabelVocabulary(object):\n",
    "    def __init__(self):\n",
    "        self._label_encoder = LabelEncoder()\n",
    "\n",
    "    def fit(self, labels):\n",
    "        self._label_encoder.fit(labels)\n",
    "\n",
    "    def to_index(self, label):\n",
    "        return self._label_encoder.transform([label])[0]\n",
    "\n",
    "    def to_indexes(self, labels):\n",
    "        return self._label_encoder.transform(labels)\n",
    "\n",
    "    def to_labels(self, indexes):\n",
    "        return self._label_encoder.inverse_transform(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b41a8083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"class Vocabulary(object):\\n    def __init__(self, lower=True):\\n        self._itow = {}  # index to word\\n        self._wtoi = {}  # word to index\\n        self._lower = lower\\n        self.PAD_TOKEN = \\\"<PAD>\\\"\\n        self.PAD_IDX = 10\\n        self.UNK_TOKEN = \\\"<UNK>\\\"\\n        self.UNK_IDX = 0\\n        self.len_vocab = 0\\n        self.max_idx = 0\\n\\n    def _tow(self, word):\\n        if self._lower:\\n            return word.lower()\\n        return word\\n\\n    def wtoi(self, word):\\n        w = self._tow(word)\\n        if w not in self._wtoi:\\n            return self.UNK_IDX\\n\\n        return self._wtoi[w]\\n\\n    def itow(self, i):\\n        if i not in self._itow:\\n            return self.UNK_TOKEN\\n\\n        return self._itow[i]\\n\\n    def fit(self, texts):\\n        i = 100\\n        for text in tqdm(texts):\\n            for word in text.split():\\n                w = self._tow(word)\\n\\n                if w not in self._wtoi:\\n                    self._wtoi[w] = i\\n                    self._itow[i] = w\\n                    i += 1\\n                    self.len_vocab = i - 100\\n                    self.max_idx = i\\n        return self\\n\\n    def to_padded_idx(self, text, max_seq_len=256):\\n        padded_idxs = []\\n        for word in text.split()[:max_seq_len]:\\n            w = self._tow(word)\\n            word_index = self.wtoi(w)\\n            padded_idxs.append(word_index)\\n\\n        if len(padded_idxs) < max_seq_len:\\n            diff = max_seq_len - len(padded_idxs)\\n            for k in range(diff):\\n                padded_idxs.append(self.PAD_IDX)\\n        return padded_idxs\\n\\n    def to_padded_idxs(self, texts, max_seq_len=256):\\n        res = []\\n        for text in tqdm(texts):\\n            res.append(self.to_padded_idx(text))\\n        return res\\n\\n    def __len__(self):\\n        return self.len_vocab\";\n",
       "                var nbb_formatted_code = \"class Vocabulary(object):\\n    def __init__(self, lower=True):\\n        self._itow = {}  # index to word\\n        self._wtoi = {}  # word to index\\n        self._lower = lower\\n        self.PAD_TOKEN = \\\"<PAD>\\\"\\n        self.PAD_IDX = 10\\n        self.UNK_TOKEN = \\\"<UNK>\\\"\\n        self.UNK_IDX = 0\\n        self.len_vocab = 0\\n        self.max_idx = 0\\n\\n    def _tow(self, word):\\n        if self._lower:\\n            return word.lower()\\n        return word\\n\\n    def wtoi(self, word):\\n        w = self._tow(word)\\n        if w not in self._wtoi:\\n            return self.UNK_IDX\\n\\n        return self._wtoi[w]\\n\\n    def itow(self, i):\\n        if i not in self._itow:\\n            return self.UNK_TOKEN\\n\\n        return self._itow[i]\\n\\n    def fit(self, texts):\\n        i = 100\\n        for text in tqdm(texts):\\n            for word in text.split():\\n                w = self._tow(word)\\n\\n                if w not in self._wtoi:\\n                    self._wtoi[w] = i\\n                    self._itow[i] = w\\n                    i += 1\\n                    self.len_vocab = i - 100\\n                    self.max_idx = i\\n        return self\\n\\n    def to_padded_idx(self, text, max_seq_len=256):\\n        padded_idxs = []\\n        for word in text.split()[:max_seq_len]:\\n            w = self._tow(word)\\n            word_index = self.wtoi(w)\\n            padded_idxs.append(word_index)\\n\\n        if len(padded_idxs) < max_seq_len:\\n            diff = max_seq_len - len(padded_idxs)\\n            for k in range(diff):\\n                padded_idxs.append(self.PAD_IDX)\\n        return padded_idxs\\n\\n    def to_padded_idxs(self, texts, max_seq_len=256):\\n        res = []\\n        for text in tqdm(texts):\\n            res.append(self.to_padded_idx(text))\\n        return res\\n\\n    def __len__(self):\\n        return self.len_vocab\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Vocabulary(object):\n",
    "    def __init__(self, lower=True):\n",
    "        self._itow = {}  # index to word\n",
    "        self._wtoi = {}  # word to index\n",
    "        self._lower = lower\n",
    "        self.PAD_TOKEN = \"<PAD>\"\n",
    "        self.PAD_IDX = 10\n",
    "        self.UNK_TOKEN = \"<UNK>\"\n",
    "        self.UNK_IDX = 0\n",
    "        self.len_vocab = 0\n",
    "        self.max_idx = 0\n",
    "\n",
    "    def _tow(self, word):\n",
    "        if self._lower:\n",
    "            return word.lower()\n",
    "        return word\n",
    "\n",
    "    def wtoi(self, word):\n",
    "        w = self._tow(word)\n",
    "        if w not in self._wtoi:\n",
    "            return self.UNK_IDX\n",
    "\n",
    "        return self._wtoi[w]\n",
    "\n",
    "    def itow(self, i):\n",
    "        if i not in self._itow:\n",
    "            return self.UNK_TOKEN\n",
    "\n",
    "        return self._itow[i]\n",
    "\n",
    "    def fit(self, texts):\n",
    "        i = 100\n",
    "        for text in tqdm(texts):\n",
    "            for word in text.split():\n",
    "                w = self._tow(word)\n",
    "\n",
    "                if w not in self._wtoi:\n",
    "                    self._wtoi[w] = i\n",
    "                    self._itow[i] = w\n",
    "                    i += 1\n",
    "                    self.len_vocab = i - 100\n",
    "                    self.max_idx = i\n",
    "        return self\n",
    "\n",
    "    def to_padded_idx(self, text, max_seq_len=256):\n",
    "        padded_idxs = []\n",
    "        for word in text.split()[:max_seq_len]:\n",
    "            w = self._tow(word)\n",
    "            word_index = self.wtoi(w)\n",
    "            padded_idxs.append(word_index)\n",
    "\n",
    "        if len(padded_idxs) < max_seq_len:\n",
    "            diff = max_seq_len - len(padded_idxs)\n",
    "            for k in range(diff):\n",
    "                padded_idxs.append(self.PAD_IDX)\n",
    "        return padded_idxs\n",
    "\n",
    "    def to_padded_idxs(self, texts, max_seq_len=256):\n",
    "        res = []\n",
    "        for text in tqdm(texts):\n",
    "            res.append(self.to_padded_idx(text))\n",
    "        return res\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aef3697e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695e5008f2c049b5ba2d4b6bdb9760a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Vocabulary at 0x7f870a96ce20>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"vocabulary = Vocabulary()\\nvocabulary.fit(X_train)\";\n",
       "                var nbb_formatted_code = \"vocabulary = Vocabulary()\\nvocabulary.fit(X_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocabulary = Vocabulary()\n",
    "vocabulary.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "effdda89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"label_vocabulary = LabelVocabulary()\\nlabel_vocabulary.fit(y_train)\";\n",
       "                var nbb_formatted_code = \"label_vocabulary = LabelVocabulary()\\nlabel_vocabulary.fit(y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_vocabulary = LabelVocabulary()\n",
    "label_vocabulary.fit(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce0d854",
   "metadata": {},
   "source": [
    "Then I will need to create `Dataset` abstraction that will be used by `pytorch` to load data, from\n",
    "```\n",
    "texts = [\n",
    "    'some text here',\n",
    "    ...\n",
    "],\n",
    "labels = [\n",
    "    'entertainment',\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "to \n",
    "```\n",
    "{\n",
    "    'input_ids': [\n",
    "        [20, 52, 78 ...], # assuming 'some' -> 20, 'text' -> 52, 'here' -> 78 by Vocabulary\n",
    "        ...\n",
    "    ],\n",
    "    'label': [\n",
    "        0, # assuming 0 -> 'entertainment' by LabelVocabulary\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68f74983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"class SimpleDataset(Dataset):\\n    def __init__(self, vocab, label_vocab, texts, labels=None, max_seq_len=256):\\n        self._vocab = vocab\\n        self._label_vocab = label_vocab\\n        self._texts = texts\\n        self._labels = labels\\n        self._max_seq_len = max_seq_len\\n\\n    def __len__(self):\\n        return len(self._texts)\\n\\n    def __getitem__(self, idx):\\n        result = {}\\n        result[\\\"input_ids\\\"] = torch.tensor(\\n            self._vocab.to_padded_idx(self._texts[idx], max_seq_len=self._max_seq_len),\\n            dtype=torch.long,\\n        )\\n\\n        if self._labels is not None:\\n            result[\\\"label\\\"] = torch.tensor(\\n                self._label_vocab.to_index(self._labels[idx]), dtype=torch.long\\n            )\\n        return result\";\n",
       "                var nbb_formatted_code = \"class SimpleDataset(Dataset):\\n    def __init__(self, vocab, label_vocab, texts, labels=None, max_seq_len=256):\\n        self._vocab = vocab\\n        self._label_vocab = label_vocab\\n        self._texts = texts\\n        self._labels = labels\\n        self._max_seq_len = max_seq_len\\n\\n    def __len__(self):\\n        return len(self._texts)\\n\\n    def __getitem__(self, idx):\\n        result = {}\\n        result[\\\"input_ids\\\"] = torch.tensor(\\n            self._vocab.to_padded_idx(self._texts[idx], max_seq_len=self._max_seq_len),\\n            dtype=torch.long,\\n        )\\n\\n        if self._labels is not None:\\n            result[\\\"label\\\"] = torch.tensor(\\n                self._label_vocab.to_index(self._labels[idx]), dtype=torch.long\\n            )\\n        return result\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, vocab, label_vocab, texts, labels=None, max_seq_len=256):\n",
    "        self._vocab = vocab\n",
    "        self._label_vocab = label_vocab\n",
    "        self._texts = texts\n",
    "        self._labels = labels\n",
    "        self._max_seq_len = max_seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        result = {}\n",
    "        result[\"input_ids\"] = torch.tensor(\n",
    "            self._vocab.to_padded_idx(self._texts[idx], max_seq_len=self._max_seq_len),\n",
    "            dtype=torch.long,\n",
    "        )\n",
    "\n",
    "        if self._labels is not None:\n",
    "            result[\"label\"] = torch.tensor(\n",
    "                self._label_vocab.to_index(self._labels[idx]), dtype=torch.long\n",
    "            )\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5da2708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"train_dataset = SimpleDataset(vocabulary, label_vocabulary, X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"train_dataset = SimpleDataset(vocabulary, label_vocabulary, X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = SimpleDataset(vocabulary, label_vocabulary, X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58e0ba54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"test_dataset = SimpleDataset(vocabulary, label_vocabulary, X_test, y_test)\\ntest_dataloader = DataLoader(test_dataset, batch_size=8)\";\n",
       "                var nbb_formatted_code = \"test_dataset = SimpleDataset(vocabulary, label_vocabulary, X_test, y_test)\\ntest_dataloader = DataLoader(test_dataset, batch_size=8)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = SimpleDataset(vocabulary, label_vocabulary, X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6694dc32",
   "metadata": {},
   "source": [
    "I will then train a simple model, which has this architecture\n",
    "\n",
    "[![svg](https://mermaid.ink/img/eyJjb2RlIjoiZ3JhcGggTFJcbiAgIEkoKGlucHV0KSkgLS0-IEUoKGVtYmVkZGluZykpXG4gICBFIC0tPiBDKChDTk4gMUQpKVxuICAgQyAtLT4gUFtNYXggUG9vbCAxRF1cbiAgIFAgLS0-IEwoKExpbmVhcikpXG4gICAiLCJtZXJtYWlkIjp7InRoZW1lIjoiZGVmYXVsdCJ9LCJ1cGRhdGVFZGl0b3IiOmZhbHNlLCJhdXRvU3luYyI6dHJ1ZSwidXBkYXRlRGlhZ3JhbSI6ZmFsc2V9)](https://mermaid-js.github.io/mermaid-live-editor/edit##eyJjb2RlIjoiZ3JhcGggTFJcbiAgIEkoKGlucHV0KSkgLS0-IEUoKGVtYmVkZGluZykpXG4gICBFIC0tPiBDKChDTk4gMUQpKVxuICAgQyAtLT4gUFtNYXggUG9vbCAxRF1cbiAgIFAgLS0-IEwoKExpbmVhKSlcbiAgICIsIm1lcm1haWQiOiJ7XG4gIFwidGhlbWVcIjogXCJkZWZhdWx0XCJcbn0iLCJ1cGRhdGVFZGl0b3IiOmZhbHNlLCJhdXRvU3luYyI6dHJ1ZSwidXBkYXRlRGlhZ3JhbSI6ZmFsc2V9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd63d1e7",
   "metadata": {},
   "source": [
    "The idea is to train a simple classifier and connect the interim output (until Max Pool 1D) back to the ngrams of the sentences.\n",
    "\n",
    "\n",
    "Here I will define ngrams to be 3, hence the $\\text{kernel size} = \\text{ngrams} = 3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0dd639f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"class ModelConfig(object):\\n    def __init__(self, vocabulary, label_vocabulary, seq_len=256):\\n        self.vocab_size = vocabulary.max_idx + 1\\n        self.embed_dim = 100\\n        self.cnn_output_dim = 50\\n        self.n_grams = 3  # kernel_size\\n        self.cls_in_dim = (seq_len - (self.n_grams - 1)) // self.n_grams\\n        self.n_class = len(label_vocabulary._label_encoder.classes_)\\n        self.seq_len = seq_len\\n\\n\\nclass SimpleModel(nn.Module):\\n    def __init__(self, config):\\n        super().__init__()\\n        self.embed = nn.Embedding(config.vocab_size, config.embed_dim)\\n        self.cnn = nn.Conv1d(config.embed_dim, config.cnn_output_dim, config.n_grams)\\n        self.max_pool = nn.MaxPool1d(config.n_grams)\\n\\n        self.classifier = nn.Linear(\\n            config.cls_in_dim * config.cnn_output_dim, config.n_class\\n        )\\n\\n    def forward(self, x):\\n        batch_size, seq_len = x.shape\\n        # (batch_size, seq_len, embed_dim)\\n        z = self.embed(x)\\n        # (batch_size, embed_dim, seq_len)\\n        z = z.permute(0, 2, 1)\\n        # (batch_size, cnn_output_dim - kernel_size + 1, seq_len)\\n        z = self.cnn(z)\\n        # max_pool: (batch_size, (cnn_output_dim - kernel_size + 1) / kernel_size, seq_len)\\n        # view: (batch_size, seq_len * (cnn_output_dim - kernel_size + 1) / kernel_size)\\n        z = self.max_pool(z).view(batch_size, -1)\\n        # (batch_size, n_class)\\n        logits = self.classifier(z)\\n        return logits\";\n",
       "                var nbb_formatted_code = \"class ModelConfig(object):\\n    def __init__(self, vocabulary, label_vocabulary, seq_len=256):\\n        self.vocab_size = vocabulary.max_idx + 1\\n        self.embed_dim = 100\\n        self.cnn_output_dim = 50\\n        self.n_grams = 3  # kernel_size\\n        self.cls_in_dim = (seq_len - (self.n_grams - 1)) // self.n_grams\\n        self.n_class = len(label_vocabulary._label_encoder.classes_)\\n        self.seq_len = seq_len\\n\\n\\nclass SimpleModel(nn.Module):\\n    def __init__(self, config):\\n        super().__init__()\\n        self.embed = nn.Embedding(config.vocab_size, config.embed_dim)\\n        self.cnn = nn.Conv1d(config.embed_dim, config.cnn_output_dim, config.n_grams)\\n        self.max_pool = nn.MaxPool1d(config.n_grams)\\n\\n        self.classifier = nn.Linear(\\n            config.cls_in_dim * config.cnn_output_dim, config.n_class\\n        )\\n\\n    def forward(self, x):\\n        batch_size, seq_len = x.shape\\n        # (batch_size, seq_len, embed_dim)\\n        z = self.embed(x)\\n        # (batch_size, embed_dim, seq_len)\\n        z = z.permute(0, 2, 1)\\n        # (batch_size, cnn_output_dim - kernel_size + 1, seq_len)\\n        z = self.cnn(z)\\n        # max_pool: (batch_size, (cnn_output_dim - kernel_size + 1) / kernel_size, seq_len)\\n        # view: (batch_size, seq_len * (cnn_output_dim - kernel_size + 1) / kernel_size)\\n        z = self.max_pool(z).view(batch_size, -1)\\n        # (batch_size, n_class)\\n        logits = self.classifier(z)\\n        return logits\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ModelConfig(object):\n",
    "    def __init__(self, vocabulary, label_vocabulary, seq_len=256):\n",
    "        self.vocab_size = vocabulary.max_idx + 1\n",
    "        self.embed_dim = 100\n",
    "        self.cnn_output_dim = 50\n",
    "        self.n_grams = 3  # kernel_size\n",
    "        self.cls_in_dim = (seq_len - (self.n_grams - 1)) // self.n_grams\n",
    "        self.n_class = len(label_vocabulary._label_encoder.classes_)\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(config.vocab_size, config.embed_dim)\n",
    "        self.cnn = nn.Conv1d(config.embed_dim, config.cnn_output_dim, config.n_grams)\n",
    "        self.max_pool = nn.MaxPool1d(config.n_grams)\n",
    "\n",
    "        self.classifier = nn.Linear(\n",
    "            config.cls_in_dim * config.cnn_output_dim, config.n_class\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len = x.shape\n",
    "        # (batch_size, seq_len, embed_dim)\n",
    "        z = self.embed(x)\n",
    "        # (batch_size, embed_dim, seq_len)\n",
    "        z = z.permute(0, 2, 1)\n",
    "        # (batch_size, cnn_output_dim - kernel_size + 1, seq_len)\n",
    "        z = self.cnn(z)\n",
    "        # max_pool: (batch_size, (cnn_output_dim - kernel_size + 1) / kernel_size, seq_len)\n",
    "        # view: (batch_size, seq_len * (cnn_output_dim - kernel_size + 1) / kernel_size)\n",
    "        z = self.max_pool(z).view(batch_size, -1)\n",
    "        # (batch_size, n_class)\n",
    "        logits = self.classifier(z)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42b49715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"def accuracy(y_true, y_pred):\\n    batch_size = y_true.shape[0]\\n    return (y_true == y_pred).sum().item() / batch_size\";\n",
       "                var nbb_formatted_code = \"def accuracy(y_true, y_pred):\\n    batch_size = y_true.shape[0]\\n    return (y_true == y_pred).sum().item() / batch_size\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    batch_size = y_true.shape[0]\n",
    "    return (y_true == y_pred).sum().item() / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ab3c036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"def to_ngram_probs(indices, window_size):\\n    batch_size, out_channel_size, pool_size = indices.shape\\n    batches_w = []\\n    batches = []\\n    for b in range(batch_size):\\n        w = []\\n        x = []\\n        for p in range(pool_size):\\n            indicies_slice = indices[b][:, p]\\n            counts = torch.bincount(indicies_slice, minlength=window_size)\\n            probs = counts / counts.sum()\\n            w.append(counts)\\n            x.append(probs)\\n        batches_w.append(torch.stack(w))\\n        batches.append(torch.stack(x))\\n    return torch.stack(batches_w), torch.stack(batches)\";\n",
       "                var nbb_formatted_code = \"def to_ngram_probs(indices, window_size):\\n    batch_size, out_channel_size, pool_size = indices.shape\\n    batches_w = []\\n    batches = []\\n    for b in range(batch_size):\\n        w = []\\n        x = []\\n        for p in range(pool_size):\\n            indicies_slice = indices[b][:, p]\\n            counts = torch.bincount(indicies_slice, minlength=window_size)\\n            probs = counts / counts.sum()\\n            w.append(counts)\\n            x.append(probs)\\n        batches_w.append(torch.stack(w))\\n        batches.append(torch.stack(x))\\n    return torch.stack(batches_w), torch.stack(batches)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def to_ngram_probs(indices, window_size):\n",
    "    batch_size, out_channel_size, pool_size = indices.shape\n",
    "    batches_w = []\n",
    "    batches = []\n",
    "    for b in range(batch_size):\n",
    "        w = []\n",
    "        x = []\n",
    "        for p in range(pool_size):\n",
    "            indicies_slice = indices[b][:, p]\n",
    "            counts = torch.bincount(indicies_slice, minlength=window_size)\n",
    "            probs = counts / counts.sum()\n",
    "            w.append(counts)\n",
    "            x.append(probs)\n",
    "        batches_w.append(torch.stack(w))\n",
    "        batches.append(torch.stack(x))\n",
    "    return torch.stack(batches_w), torch.stack(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cedf989a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"SPAN_START = '<span style=\\\"background-color: #FFFF00\\\">'\\nSPAN_END = \\\"</span>\\\"\\n\\n\\ndef visualize_sentence(sentence, highlight_indexes):\\n    result = []\\n    temp_indexes = copy(highlight_indexes)\\n    for i in range(len(sentence)):\\n        start = -1\\n        end = -1\\n        if len(temp_indexes) > 0:\\n            start, end = temp_indexes[0]\\n\\n        if i == start:\\n            result.append(SPAN_START)\\n\\n        result.append(sentence[i])\\n\\n        if i == end:\\n            result.append(SPAN_END)\\n            temp_indexes.pop(0)\\n\\n    display(HTML(\\\" \\\".join(result)))\";\n",
       "                var nbb_formatted_code = \"SPAN_START = '<span style=\\\"background-color: #FFFF00\\\">'\\nSPAN_END = \\\"</span>\\\"\\n\\n\\ndef visualize_sentence(sentence, highlight_indexes):\\n    result = []\\n    temp_indexes = copy(highlight_indexes)\\n    for i in range(len(sentence)):\\n        start = -1\\n        end = -1\\n        if len(temp_indexes) > 0:\\n            start, end = temp_indexes[0]\\n\\n        if i == start:\\n            result.append(SPAN_START)\\n\\n        result.append(sentence[i])\\n\\n        if i == end:\\n            result.append(SPAN_END)\\n            temp_indexes.pop(0)\\n\\n    display(HTML(\\\" \\\".join(result)))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SPAN_START = '<span style=\"background-color: #FFFF00\">'\n",
    "SPAN_END = \"</span>\"\n",
    "\n",
    "\n",
    "def visualize_sentence(sentence, highlight_indexes):\n",
    "    result = []\n",
    "    temp_indexes = copy(highlight_indexes)\n",
    "    for i in range(len(sentence)):\n",
    "        start = -1\n",
    "        end = -1\n",
    "        if len(temp_indexes) > 0:\n",
    "            start, end = temp_indexes[0]\n",
    "\n",
    "        if i == start:\n",
    "            result.append(SPAN_START)\n",
    "\n",
    "        result.append(sentence[i])\n",
    "\n",
    "        if i == end:\n",
    "            result.append(SPAN_END)\n",
    "            temp_indexes.pop(0)\n",
    "\n",
    "    display(HTML(\" \".join(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "37b87204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 86;\n",
       "                var nbb_unformatted_code = \"def to_highlight_indexes(important_ngram_idx, ngram_window=2):\\n    highlight_indexes_batch = []\\n    last_batch_idx = -1\\n\\n    for batch_idx, ngram_idx in important_ngram_idx:\\n        if batch_idx > last_batch_idx:\\n            highlight_indexes_batch.append([])\\n            last_batch_idx = batch_idx\\n\\n        start_ngram_idx = ngram_idx\\n        end_ngram_idx = start_ngram_idx + ngram_window\\n        highlight_indexes_batch[-1].append((start_ngram_idx, end_ngram_idx))\\n\\n    return highlight_indexes_batch\";\n",
       "                var nbb_formatted_code = \"def to_highlight_indexes(important_ngram_idx, ngram_window=2):\\n    highlight_indexes_batch = []\\n    last_batch_idx = -1\\n\\n    for batch_idx, ngram_idx in important_ngram_idx:\\n        if batch_idx > last_batch_idx:\\n            highlight_indexes_batch.append([])\\n            last_batch_idx = batch_idx\\n\\n        start_ngram_idx = ngram_idx\\n        end_ngram_idx = start_ngram_idx + ngram_window\\n        highlight_indexes_batch[-1].append((start_ngram_idx, end_ngram_idx))\\n\\n    return highlight_indexes_batch\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def to_highlight_indexes(important_ngram_idx, ngram_window=2):\n",
    "    highlight_indexes_batch = []\n",
    "    last_batch_idx = -1\n",
    "\n",
    "    for batch_idx, ngram_idx in important_ngram_idx:\n",
    "        if batch_idx > last_batch_idx:\n",
    "            highlight_indexes_batch.append([])\n",
    "            last_batch_idx = batch_idx\n",
    "\n",
    "        start_ngram_idx = ngram_idx\n",
    "        end_ngram_idx = start_ngram_idx + ngram_window\n",
    "        highlight_indexes_batch[-1].append((start_ngram_idx, end_ngram_idx))\n",
    "\n",
    "    return highlight_indexes_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcb0fdfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"def to_words(vocab, batched_ids):\\n    sentences = []\\n    for batch in batched_ids:\\n        sentences.append([vocab.itow(token_id) for token_id in batch])\\n\\n    return sentences\";\n",
       "                var nbb_formatted_code = \"def to_words(vocab, batched_ids):\\n    sentences = []\\n    for batch in batched_ids:\\n        sentences.append([vocab.itow(token_id) for token_id in batch])\\n\\n    return sentences\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def to_words(vocab, batched_ids):\n",
    "    sentences = []\n",
    "    for batch in batched_ids:\n",
    "        sentences.append([vocab.itow(token_id) for token_id in batch])\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9962da38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"device = \\\"cuda\\\"\";\n",
       "                var nbb_formatted_code = \"device = \\\"cuda\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# here I'll use GPU, but CPU will work just fine\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "007c1e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"model_config = ModelConfig(vocabulary, label_vocabulary)\\nmodel = SimpleModel(model_config).to(device)\\noptimizer = Adam(lr=1e-3, params=model.parameters())\";\n",
       "                var nbb_formatted_code = \"model_config = ModelConfig(vocabulary, label_vocabulary)\\nmodel = SimpleModel(model_config).to(device)\\noptimizer = Adam(lr=1e-3, params=model.parameters())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_config = ModelConfig(vocabulary, label_vocabulary)\n",
    "model = SimpleModel(model_config).to(device)\n",
    "optimizer = Adam(lr=1e-3, params=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "928b3b1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf3a3bb082440c8b76aaa4f43dee9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arie/miniconda3/envs/da38/lib/python3.8/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"n_epochs = 10\\npbar = tqdm(range(n_epochs))\\nfor epoch in pbar:\\n    epoch_losses = []\\n    epoch_accuracies = []\\n\\n    for batch in train_dataloader:\\n        optimizer.zero_grad()\\n        logits = model(batch[\\\"input_ids\\\"].to(device))\\n        _, y_pred = logits.max(dim=1)\\n        labels = batch[\\\"label\\\"].to(device)\\n        loss = F.cross_entropy(logits, labels)\\n        batch_loss = loss.item()\\n\\n        epoch_losses.append(batch_loss)\\n        epoch_accuracies.append(accuracy(labels, y_pred))\\n\\n        loss.backward()\\n        optimizer.step()\\n\\n    mean_epoch_losses = np.mean(epoch_losses)\\n    mean_epoch_acc = np.mean(epoch_accuracies)\\n    pbar.set_description(f\\\"[E]loss: {mean_epoch_losses:.3f}, acc: {mean_epoch_acc:.2f}\\\")\";\n",
       "                var nbb_formatted_code = \"n_epochs = 10\\npbar = tqdm(range(n_epochs))\\nfor epoch in pbar:\\n    epoch_losses = []\\n    epoch_accuracies = []\\n\\n    for batch in train_dataloader:\\n        optimizer.zero_grad()\\n        logits = model(batch[\\\"input_ids\\\"].to(device))\\n        _, y_pred = logits.max(dim=1)\\n        labels = batch[\\\"label\\\"].to(device)\\n        loss = F.cross_entropy(logits, labels)\\n        batch_loss = loss.item()\\n\\n        epoch_losses.append(batch_loss)\\n        epoch_accuracies.append(accuracy(labels, y_pred))\\n\\n        loss.backward()\\n        optimizer.step()\\n\\n    mean_epoch_losses = np.mean(epoch_losses)\\n    mean_epoch_acc = np.mean(epoch_accuracies)\\n    pbar.set_description(f\\\"[E]loss: {mean_epoch_losses:.3f}, acc: {mean_epoch_acc:.2f}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "pbar = tqdm(range(n_epochs))\n",
    "for epoch in pbar:\n",
    "    epoch_losses = []\n",
    "    epoch_accuracies = []\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(batch[\"input_ids\"].to(device))\n",
    "        _, y_pred = logits.max(dim=1)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        batch_loss = loss.item()\n",
    "\n",
    "        epoch_losses.append(batch_loss)\n",
    "        epoch_accuracies.append(accuracy(labels, y_pred))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    mean_epoch_losses = np.mean(epoch_losses)\n",
    "    mean_epoch_acc = np.mean(epoch_accuracies)\n",
    "    pbar.set_description(f\"[E]loss: {mean_epoch_losses:.3f}, acc: {mean_epoch_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a15facd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827cedd6d9544f0dba8307cc722e6120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"with torch.no_grad():\\n    test_accuracies = []\\n    test_losses = []\\n    pbar = tqdm(test_dataloader)\\n    \\n    for batch in pbar:\\n        logits = model(batch['input_ids'].to(device))\\n        _, y_pred = logits.max(dim=1)\\n        labels = batch['label'].to(device)\\n        loss = F.cross_entropy(logits, labels)\\n        batch_loss = loss.item()\\n        \\n        test_losses.append(batch_loss)\\n        test_accuracies.append(accuracy(labels, y_pred))\\n        \\n        mean_test_loss = np.mean(test_losses)\\n        mean_test_accuracy = np.mean(test_accuracies)\\n        pbar.set_description(f'[T]loss: {mean_test_loss:.3f}, acc: {mean_test_accuracy:.2f}')\";\n",
       "                var nbb_formatted_code = \"with torch.no_grad():\\n    test_accuracies = []\\n    test_losses = []\\n    pbar = tqdm(test_dataloader)\\n\\n    for batch in pbar:\\n        logits = model(batch[\\\"input_ids\\\"].to(device))\\n        _, y_pred = logits.max(dim=1)\\n        labels = batch[\\\"label\\\"].to(device)\\n        loss = F.cross_entropy(logits, labels)\\n        batch_loss = loss.item()\\n\\n        test_losses.append(batch_loss)\\n        test_accuracies.append(accuracy(labels, y_pred))\\n\\n        mean_test_loss = np.mean(test_losses)\\n        mean_test_accuracy = np.mean(test_accuracies)\\n        pbar.set_description(\\n            f\\\"[T]loss: {mean_test_loss:.3f}, acc: {mean_test_accuracy:.2f}\\\"\\n        )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_accuracies = []\n",
    "    test_losses = []\n",
    "    pbar = tqdm(test_dataloader)\n",
    "\n",
    "    for batch in pbar:\n",
    "        logits = model(batch[\"input_ids\"].to(device))\n",
    "        _, y_pred = logits.max(dim=1)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        batch_loss = loss.item()\n",
    "\n",
    "        test_losses.append(batch_loss)\n",
    "        test_accuracies.append(accuracy(labels, y_pred))\n",
    "\n",
    "        mean_test_loss = np.mean(test_losses)\n",
    "        mean_test_accuracy = np.mean(test_accuracies)\n",
    "        pbar.set_description(\n",
    "            f\"[T]loss: {mean_test_loss:.3f}, acc: {mean_test_accuracy:.2f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a58b15",
   "metadata": {},
   "source": [
    "Let's peek at the test accuracies per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "df5d4b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 114;\n",
       "                var nbb_unformatted_code = \"plt.boxplot(test_accuracies)\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"plt.boxplot(test_accuracies)\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(test_accuracies)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a9c61",
   "metadata": {},
   "source": [
    "it seems that my simple model has done pretty good job in this text classification dataset, it has median of ~75% accuracy for test dataset.\n",
    "\n",
    "Now I will take a sample from test dataloader and see what will the CNN + pooling detect in our sentences ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b399af1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"test_sample = next(iter(test_dataloader))\";\n",
       "                var nbb_formatted_code = \"test_sample = next(iter(test_dataloader))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_sample = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be3b692f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"with torch.no_grad():\\n    embedded = model.embed(test_sample[\\\"input_ids\\\"].to(device))\\n    embedded = embedded.permute(0, 2, 1)\\n    result = model.cnn(embedded)\";\n",
       "                var nbb_formatted_code = \"with torch.no_grad():\\n    embedded = model.embed(test_sample[\\\"input_ids\\\"].to(device))\\n    embedded = embedded.permute(0, 2, 1)\\n    result = model.cnn(embedded)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    embedded = model.embed(test_sample[\"input_ids\"].to(device))\n",
    "    embedded = embedded.permute(0, 2, 1)\n",
    "    result = model.cnn(embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a831b53",
   "metadata": {},
   "source": [
    "here I used `max_pool1d_with_indices` so that I can also extract the `indices` of max on each sliding window. It pretty much doing the argmax of each sliding window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bcecfd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# max_pooled (batch_size, seq_len, n_slide/kernel_size)\\n# indices (batch_size, seq_len, n_slide/kernel_size)\\nmax_pooled, indices = F.max_pool1d_with_indices(result, 3)\";\n",
       "                var nbb_formatted_code = \"# max_pooled (batch_size, seq_len, n_slide/kernel_size)\\n# indices (batch_size, seq_len, n_slide/kernel_size)\\nmax_pooled, indices = F.max_pool1d_with_indices(result, 3)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# max_pooled (batch_size, seq_len, n_slide/kernel_size)\n",
    "# indices (batch_size, seq_len, n_slide/kernel_size)\n",
    "max_pooled, indices = F.max_pool1d_with_indices(result, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013ebca2",
   "metadata": {},
   "source": [
    "then I will construct `n_gram_counts` with shape `[batch_size, pooled_size, n_sliding_windows]` that looks like this\n",
    "```\n",
    "[\n",
    "    # batch 1\n",
    "    [\n",
    "      [10, 5, 7, 0,  0, 0],\n",
    "      [ 0, 9, 8, 4,  0, 0],\n",
    "      [ 0, 0, 3, 4, 10, 0],\n",
    "      ...\n",
    "    ],\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "for \n",
    "\n",
    "$\\text{sequence length} = 256$\n",
    "\n",
    "$\\text{kernel size} = 3$\n",
    "\n",
    "then (also assuming other parameters for CNN is left to default)\n",
    "\n",
    "$$\\text{n sliding windows} = \\text{sequence length} - \\text{kernel size} + 1 = 254$$\n",
    "\n",
    "$$\\text{pooled size} = floor(\\frac{\\text{n sliding windows}}{\\text{kernel size}}) = 84 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b81a45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"n_gram_counts, n_gram_probs = to_ngram_probs(indices, 254)\";\n",
       "                var nbb_formatted_code = \"n_gram_counts, n_gram_probs = to_ngram_probs(indices, 254)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# n_gram_counts (batch_size, pooled_size, cnn_output_size)\n",
    "n_gram_counts, _ = to_ngram_probs(indices, 254)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de33e2e",
   "metadata": {},
   "source": [
    "Then for each sliding windows (was 254 in the previous explanation), we wanted to see which sliding windows are the most important. One way to do that is by summing the count in axis=1 and divide it with maximum of the counts, see this example for illustration\n",
    "```\n",
    "[\n",
    "    # batch 1\n",
    "    [\n",
    "      [10,  5,  7, 0,  0, 0],\n",
    "      [ 0,  9,  8, 4,  0, 0],\n",
    "      [ 0,  0,  3, 4, 10, 0],\n",
    "      ...\n",
    "      |\n",
    "      |\n",
    "      v\n",
    "      \n",
    "      [10, 14, 18, 8,  0, 0],\n",
    "      \n",
    "      |\n",
    "      |\n",
    "      v\n",
    "      [0.55, 0.78, 1.0, 0.44,  0, 0], # divide all by max of those counts, which is 18\n",
    "    ],\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb2f47f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"sum_per_sliding_windows = n_gram_counts.sum(axis=1)\\nmax_per_batch, _ = sum_per_sliding_windows.max(axis=1)\";\n",
       "                var nbb_formatted_code = \"sum_per_sliding_windows = n_gram_counts.sum(axis=1)\\nmax_per_batch, _ = sum_per_sliding_windows.max(axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum_per_sliding_windows = n_gram_counts.sum(axis=1)\n",
    "max_per_batch, _ = sum_per_sliding_windows.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "de50ab23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"prob_per_sliding_windows = sum_per_sliding_windows / max_per_batch.view(-1, 1)\";\n",
       "                var nbb_formatted_code = \"prob_per_sliding_windows = sum_per_sliding_windows / max_per_batch.view(-1, 1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prob_per_sliding_windows = sum_per_sliding_windows / max_per_batch.view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c616e9",
   "metadata": {},
   "source": [
    "Now I'm gonna set arbitrary threshold, **0.8**, which seems make sense to me, so that we can filter which sliding windows are seems to be very important from the model point of view and neglect the sliding windows which less than that threshold.\n",
    "\n",
    "```\n",
    "[\n",
    "  [0.55, 0.78, 1.0, 0.44,  0, 0]\n",
    "  \n",
    "  |\n",
    "  |\n",
    "  v\n",
    "  [0, 0, 1.0, 0,  0, 0] # zero out all that less than 0.8\n",
    "  \n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "045af9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"threshold = 0.8\\n\\nimportant_sliding_windows = torch.where(\\n    (prob_per_sliding_windows > threshold) & (prob_per_sliding_windows <= 1.0),\\n    prob_per_sliding_windows,\\n    torch.zeros_like(prob_per_sliding_windows),\\n)\";\n",
       "                var nbb_formatted_code = \"threshold = 0.8\\n\\nimportant_sliding_windows = torch.where(\\n    (prob_per_sliding_windows > threshold) & (prob_per_sliding_windows <= 1.0),\\n    prob_per_sliding_windows,\\n    torch.zeros_like(prob_per_sliding_windows),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold = 0.8\n",
    "\n",
    "important_sliding_windows = torch.where(\n",
    "    (prob_per_sliding_windows > threshold) & (prob_per_sliding_windows <= 1.0),\n",
    "    prob_per_sliding_windows,\n",
    "    torch.zeros_like(prob_per_sliding_windows),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e07a7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"important_ngram_idx = (important_sliding_windows >= threshold).nonzero(as_tuple=True)[0].cpu().numpy()\";\n",
       "                var nbb_formatted_code = \"important_ngram_idx = (\\n    (important_sliding_windows >= threshold).nonzero(as_tuple=True)[0].cpu().numpy()\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "important_ngram_idx = (\n",
    "    (important_sliding_windows >= threshold).nonzero(as_tuple=True)[0].cpu().numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "27adba5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 75;\n",
       "                var nbb_unformatted_code = \"important_ngram_idx = (important_sliding_windows >= threshold).nonzero().cpu().numpy()\";\n",
       "                var nbb_formatted_code = \"important_ngram_idx = (important_sliding_windows >= threshold).nonzero().cpu().numpy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "important_ngram_idx = (important_sliding_windows >= threshold).nonzero().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6fecf87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 87;\n",
       "                var nbb_unformatted_code = \"highlight_indexes = to_highlight_indexes(important_ngram_idx)\";\n",
       "                var nbb_formatted_code = \"highlight_indexes = to_highlight_indexes(important_ngram_idx)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "highlight_indexes = to_highlight_indexes(important_ngram_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7d7b3843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 97;\n",
       "                var nbb_unformatted_code = \"sentences = to_words(vocabulary, test_sample[\\\"input_ids\\\"].cpu().numpy())\";\n",
       "                var nbb_formatted_code = \"sentences = to_words(vocabulary, test_sample[\\\"input_ids\\\"].cpu().numpy())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = to_words(vocabulary, test_sample[\"input_ids\"].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8947104a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 102;\n",
       "                var nbb_unformatted_code = \"test_labels = label_vocabulary.to_labels(test_sample['label'].cpu().numpy())\";\n",
       "                var nbb_formatted_code = \"test_labels = label_vocabulary.to_labels(test_sample[\\\"label\\\"].cpu().numpy())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_labels = label_vocabulary.to_labels(test_sample[\"label\"].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ed1f24",
   "metadata": {},
   "source": [
    "Now I can visualize which ngrams that my model deemed important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a1c5383d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label : entertainment\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "comeback show for friends star friends actress lisa <UNK> <span style=\"background-color: #FFFF00\"> is to play </span> the lead role in a new series about a one-time sitcom star according to the hollywood reporter. <UNK> episodes of <span style=\"background-color: #FFFF00\"> comeback have been </span> commissioned by cable channel hbo home of <span style=\"background-color: #FFFF00\"> hits such as </span> sex and the city. <UNK> who played <UNK> in friends co-wrote the pilot episode and will also act as executive producer. hbo has been looking for its next big comedy <span style=\"background-color: #FFFF00\"> hit since sex </span> and the <span style=\"background-color: #FFFF00\"> city drew to </span> a close in the us in <span style=\"background-color: #FFFF00\"> february. comeback is </span> the first <UNK> comedy series that the channel has picked up since the sex and the <span style=\"background-color: #FFFF00\"> city drew to </span> the end <span style=\"background-color: #FFFF00\"> of its <UNK> </span> friends ended its 10-year run on <span style=\"background-color: #FFFF00\"> the nbc network </span> in may and attentions have turned to which projects its six individual stars would <UNK> matt <UNK> is starring in a friends spin-off sitcom charting <span style=\"background-color: #FFFF00\"> joey s fortunes </span> in <span style=\"background-color: #FFFF00\"> los angeles as </span> he <UNK> his acting career. jennifer <UNK> who was rachel in the long-running show has enjoyed a series of <span style=\"background-color: #FFFF00\"> successful film appearances </span> with <span style=\"background-color: #FFFF00\"> further projects in </span> the <UNK> <UNK> cox <UNK> <UNK> has been working on a drama project along with husband david <UNK> for hbo called the <span style=\"background-color: #FFFF00\"> rise and fall </span> of taylor kennedy. matthew perry who played <UNK> <span style=\"background-color: #FFFF00\"> has appeared on </span> the west end stage and has a film the beginning of wisdom currently in <span style=\"background-color: #FFFF00\"> production. and david </span> <UNK> <UNK> directed during his time on friends and has also worked on <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 104;\n",
       "                var nbb_unformatted_code = \"batch_idx = 0\\n\\nprint(f'label : {test_labels[batch_idx]}' )\\nvisualize_sentence(sentences[batch_idx], highlight_indexes[batch_idx])\";\n",
       "                var nbb_formatted_code = \"batch_idx = 0\\n\\nprint(f\\\"label : {test_labels[batch_idx]}\\\")\\nvisualize_sentence(sentences[batch_idx], highlight_indexes[batch_idx])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_idx = 0\n",
    "\n",
    "print(f\"label : {test_labels[batch_idx]}\")\n",
    "visualize_sentence(sentences[batch_idx], highlight_indexes[batch_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "11d08fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label : business\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "quake s economic costs emerging asian governments and international <span style=\"background-color: #FFFF00\"> agencies are reeling </span> at the potential economic devastation left by the <span style=\"background-color: #FFFF00\"> asian tsunami and </span> <UNK> world bank president james <UNK> has said his agency is only beginning to grasp the magnitude of the disaster and its economic impact. the tragedy has left at least 25 000 people dead with sri lanka thailand india and indonesia worst hit. some early estimates of reconstruction costs are starting to emerge. millions have been left homeless while businesses and infrastructure have been washed away. economists <span style=\"background-color: #FFFF00\"> believe several of </span> the 10 countries hit by <span style=\"background-color: #FFFF00\"> the giant waves </span> could see a slowdown in growth. in sri lanka some observers have said that as much as 1% of annual growth <span style=\"background-color: #FFFF00\"> may be lost. </span> for thailand that <span style=\"background-color: #FFFF00\"> figure is much </span> lower at <UNK> governments are expected to take steps such as cutting taxes and increasing spending to facilitate a recovery. with the enormous <UNK> of <UNK> will be a serious relaxation <span style=\"background-color: #FFFF00\"> of fiscal policy </span> <UNK> <UNK> chief economist for the region at <UNK> <UNK> told agence france <UNK> the economic impact of it will certainly be large but it should not be enough to derail the momentum of the region in 2005 he said. first and <UNK> this is a human tragedy. india s economy however is less likely <span style=\"background-color: #FFFF00\"> to slow because </span> the <span style=\"background-color: #FFFF00\"> areas hit are </span> some of the <span style=\"background-color: #FFFF00\"> least developed. the </span> <span style=\"background-color: #FFFF00\"> regional giant has </span> enjoyed strong growth in 2004. but india now faces other problems with aid workers under pressure to ensure a clean"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 105;\n",
       "                var nbb_unformatted_code = \"batch_idx = 1\\nprint(f\\\"label : {test_labels[batch_idx]}\\\")\\nvisualize_sentence(sentences[batch_idx], highlight_indexes[batch_idx])\";\n",
       "                var nbb_formatted_code = \"batch_idx = 1\\nprint(f\\\"label : {test_labels[batch_idx]}\\\")\\nvisualize_sentence(sentences[batch_idx], highlight_indexes[batch_idx])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_idx = 1\n",
    "print(f\"label : {test_labels[batch_idx]}\")\n",
    "visualize_sentence(sentences[batch_idx], highlight_indexes[batch_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "560cb738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label : sport\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "robben and cole earn chelsea win <UNK> <UNK> a win against a battling portsmouth side just as it looked like the premiership leaders would have to settle for a point. <span style=\"background-color: #FFFF00\"> arjen robben curled </span> in a late deflected <UNK> shot from the right side of pompey s box to break the home side s brave <UNK> chelsea had been continually frustrated but joe cole added a second with a 20-yard shot in <UNK> nigel quashie had pompey s best <span style=\"background-color: #FFFF00\"> chance when his </span> effort was tipped over. the <span style=\"background-color: #FFFF00\"> fratton park crowd </span> were in good voice as usual and even though portsmouth more than held their own chelsea still managed to carve out two early chances. striker didier drogba snapped in an angled shot to force home keeper <UNK> hislop into a smart save while an unmarked frank lampard had a strike blocked by arjan de <UNK> but pompey chased <UNK> and <UNK> a chelsea side as the <UNK> side started to gain the upper hand and almost took the lead through <UNK> the midfielder struck a <UNK> long range shot which keeper petr cech tipped over at full <UNK> pompey stretched arsenal to the limit recently and were providing a similarly tough obstacle to overcome for a chelsea team struggling to <UNK> any pressure. velimir zajec s players <span style=\"background-color: #FFFF00\"> stood firm as </span> the <span style=\"background-color: #FFFF00\"> visitors came out </span> in lively fashion after the break but just <span style=\"background-color: #FFFF00\"> as they took </span> a stranglehold of the <span style=\"background-color: #FFFF00\"> match the visitors </span> launched a </span> <UNK> drogba spun to get a sight of goal and struck a fierce"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 115;\n",
       "                var nbb_unformatted_code = \"batch_idx = 2\\nprint(f\\\"label : {test_labels[batch_idx]}\\\")\\nvisualize_sentence(sentences[batch_idx], highlight_indexes[batch_idx])\";\n",
       "                var nbb_formatted_code = \"batch_idx = 2\\nprint(f\\\"label : {test_labels[batch_idx]}\\\")\\nvisualize_sentence(sentences[batch_idx], highlight_indexes[batch_idx])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_idx = 2\n",
    "print(f\"label : {test_labels[batch_idx]}\")\n",
    "visualize_sentence(sentences[batch_idx], highlight_indexes[batch_idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
